{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Download pdfs"
      ],
      "metadata": {
        "id": "Gssb9W75FbU8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/arpytanshu/parspec.git\n",
        "! pip install -r parspec/requirements.txt\n",
        "! mkdir -p parspec/data/test"
      ],
      "metadata": {
        "id": "kLWG1zUhFiyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4c86wTPDESrK",
        "outputId": "0223fa2c-3cdc-41e8-fc49-3d098a563c2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[|] Progress: [|                                                 ] 1% {1 / 80}\r[/] Progress: [|                                                 ] 2% {2 / 80}\r[-] Progress: [||                                                ] 4% {3 / 80}\r[\\] Progress: [||                                                ] 5% {4 / 80}\r[|] Progress: [|||                                               ] 6% {5 / 80}\r[/] Progress: [||||                                              ] 8% {6 / 80}\r[-] Progress: [||||                                              ] 9% {7 / 80}\r[\\] Progress: [|||||                                             ] 10% {8 / 80}\r[|] Progress: [||||||                                            ] 11% {9 / 80}\r[/] Progress: [||||||                                            ] 12% {10 / 80}\r[-] Progress: [|||||||                                           ] 14% {11 / 80}\r[\\] Progress: [||||||||                                          ] 15% {12 / 80}\r[|] Progress: [||||||||                                          ] 16% {13 / 80}\r[/] Progress: [|||||||||                                         ] 18% {14 / 80}\r[-] Progress: [|||||||||                                         ] 19% {15 / 80}\r[\\] Progress: [||||||||||                                        ] 20% {16 / 80}\r[|] Progress: [|||||||||||                                       ] 21% {17 / 80}\r[/] Progress: [|||||||||||                                       ] 22% {18 / 80}\r[-] Progress: [||||||||||||                                      ] 24% {19 / 80}\r[\\] Progress: [||||||||||||                                      ] 25% {20 / 80}\r[|] Progress: [|||||||||||||                                     ] 26% {21 / 80}\r[/] Progress: [||||||||||||||                                    ] 28% {22 / 80}\r[-] Progress: [||||||||||||||                                    ] 29% {23 / 80}\r[\\] Progress: [|||||||||||||||                                   ] 30% {24 / 80}\r[|] Progress: [||||||||||||||||                                  ] 31% {25 / 80}\r[/] Progress: [||||||||||||||||                                  ] 32% {26 / 80}\r[-] Progress: [|||||||||||||||||                                 ] 34% {27 / 80}\r[\\] Progress: [||||||||||||||||||                                ] 35% {28 / 80}\r[|] Progress: [||||||||||||||||||                                ] 36% {29 / 80}\r[/] Progress: [|||||||||||||||||||                               ] 38% {30 / 80}\r[-] Progress: [|||||||||||||||||||                               ] 39% {31 / 80}\r[\\] Progress: [||||||||||||||||||||                              ] 40% {32 / 80}\r[|] Progress: [|||||||||||||||||||||                             ] 41% {33 / 80}\r[/] Progress: [|||||||||||||||||||||                             ] 42% {34 / 80}\r[-] Progress: [||||||||||||||||||||||                            ] 44% {35 / 80}\r[\\] Progress: [||||||||||||||||||||||                            ] 45% {36 / 80}\r[|] Progress: [|||||||||||||||||||||||                           ] 46% {37 / 80}\r[/] Progress: [||||||||||||||||||||||||                          ] 48% {38 / 80}\r[-] Progress: [||||||||||||||||||||||||                          ] 49% {39 / 80}\r[\\] Progress: [|||||||||||||||||||||||||                         ] 50% {40 / 80}\r[|] Progress: [||||||||||||||||||||||||||                        ] 51% {41 / 80}\r[/] Progress: [||||||||||||||||||||||||||                        ] 52% {42 / 80}\r[-] Progress: [|||||||||||||||||||||||||||                       ] 54% {43 / 80}\r[\\] Progress: [||||||||||||||||||||||||||||                      ] 55% {44 / 80}\r[|] Progress: [||||||||||||||||||||||||||||                      ] 56% {45 / 80}\r[/] Progress: [|||||||||||||||||||||||||||||                     ] 57% {46 / 80}\r[-] Progress: [|||||||||||||||||||||||||||||                     ] 59% {47 / 80}\r[\\] Progress: [||||||||||||||||||||||||||||||                    ] 60% {48 / 80}\r[|] Progress: [|||||||||||||||||||||||||||||||                   ] 61% {49 / 80}\r[/] Progress: [|||||||||||||||||||||||||||||||                   ] 62% {50 / 80}\r[-] Progress: [||||||||||||||||||||||||||||||||                  ] 64% {51 / 80}\r[\\] Progress: [||||||||||||||||||||||||||||||||                  ] 65% {52 / 80}\r[|] Progress: [|||||||||||||||||||||||||||||||||                 ] 66% {53 / 80}\r[/] Progress: [||||||||||||||||||||||||||||||||||                ] 68% {54 / 80}\r[-] Progress: [||||||||||||||||||||||||||||||||||                ] 69% {55 / 80}\r[\\] Progress: [|||||||||||||||||||||||||||||||||||               ] 70% {56 / 80}\r[|] Progress: [||||||||||||||||||||||||||||||||||||              ] 71% {57 / 80}\r[/] Progress: [||||||||||||||||||||||||||||||||||||              ] 72% {58 / 80}\r[-] Progress: [|||||||||||||||||||||||||||||||||||||             ] 74% {59 / 80}\r[\\] Progress: [||||||||||||||||||||||||||||||||||||||            ] 75% {60 / 80}\r[|] Progress: [||||||||||||||||||||||||||||||||||||||            ] 76% {61 / 80}\r[/] Progress: [|||||||||||||||||||||||||||||||||||||||           ] 78% {62 / 80}\r[-] Progress: [|||||||||||||||||||||||||||||||||||||||           ] 79% {63 / 80}\r[\\] Progress: [||||||||||||||||||||||||||||||||||||||||          ] 80% {64 / 80}\r[|] Progress: [|||||||||||||||||||||||||||||||||||||||||         ] 81% {65 / 80}\r[/] Progress: [|||||||||||||||||||||||||||||||||||||||||         ] 82% {66 / 80}\r[-] Progress: [||||||||||||||||||||||||||||||||||||||||||        ] 84% {67 / 80}\r[\\] Progress: [||||||||||||||||||||||||||||||||||||||||||        ] 85% {68 / 80}\r[|] Progress: [|||||||||||||||||||||||||||||||||||||||||||       ] 86% {69 / 80}\r[/] Progress: [||||||||||||||||||||||||||||||||||||||||||||      ] 88% {70 / 80}\r[-] Progress: [||||||||||||||||||||||||||||||||||||||||||||      ] 89% {71 / 80}\r[\\] Progress: [|||||||||||||||||||||||||||||||||||||||||||||     ] 90% {72 / 80}\r[|] Progress: [||||||||||||||||||||||||||||||||||||||||||||||    ] 91% {73 / 80}\r[/] Progress: [||||||||||||||||||||||||||||||||||||||||||||||    ] 92% {74 / 80}\r[-] Progress: [|||||||||||||||||||||||||||||||||||||||||||||||   ] 94% {75 / 80}\r[\\] Progress: [||||||||||||||||||||||||||||||||||||||||||||||||  ] 95% {76 / 80}\r[|] Progress: [||||||||||||||||||||||||||||||||||||||||||||||||  ] 96% {77 / 80}\r[/] Progress: [||||||||||||||||||||||||||||||||||||||||||||||||| ] 98% {78 / 80}\r[-] Progress: [||||||||||||||||||||||||||||||||||||||||||||||||| ] 99% {79 / 80}\r[\\] Progress: [||||||||||||||||||||||||||||||||||||||||||||||||||] 100% {80 / 80}"
          ]
        }
      ],
      "source": [
        "! python parspec/download.py --meta_path=parspec/resources/parspec_test_data.csv --dst_dir_path=parspec/data/test --threads=25\n",
        "! python parspec/prep_data.py --meta_path=parspec/resources/parspec_test_data.csv --src_dir=data/test --dst_file_path=parspec/data/test-dataset.csv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from pathlib import Path\n",
        "from parspec.download import download_link\n",
        "from parspec.prep_data import extract_text_from_pdf\n",
        "\n",
        "\n",
        "\n",
        "def infer(model, tokenizer, url=None, dst_file=None, dbg=True):\n",
        "\n",
        "    if (url == None) and (dst_file == None):\n",
        "        print('No url or dst_file provided. Exiting')\n",
        "        return\n",
        "\n",
        "    if url != None:\n",
        "        dst_file = 'temp.pdf'\n",
        "        if os.path.exists(dst_file):\n",
        "            os.remove(dst_file)\n",
        "\n",
        "        if download_link(url, dst_file):\n",
        "            if dbg: print('Download successful')\n",
        "\n",
        "    try:\n",
        "        text = extract_text_from_pdf(dst_file)\n",
        "        if dbg: print('Text extraction successful')\n",
        "    except Exception as e:\n",
        "        text = ' '\n",
        "        if dbg: print('Text extraction from pdf failed:', e)\n",
        "\n",
        "    input_ids = tokenizer.encode(text)\n",
        "    input_ids = input_ids[:min(len(input_ids), model.config.max_position_embeddings)]\n",
        "    input_ids = torch.tensor(input_ids).view(1, -1)\n",
        "    input_ids = input_ids.to(model.device)\n",
        "    with torch.no_grad():\n",
        "\n",
        "        outputs = model(input_ids)\n",
        "    class_ix = outputs.logits.argmax(1).item()\n",
        "    nl_class = {1: 'Is lighting product? YES', 0: 'Is lighting product? NO'}[class_ix]\n",
        "    if dbg: print(nl_class)\n",
        "\n",
        "    if os.path.exists('temp.pdf'):\n",
        "        os.remove('temp.pdf')\n",
        "\n",
        "    return class_ix\n",
        "\n",
        "\n",
        "def evaluate(chkpt_path, files_basepath, test_meta_df='parspec/data/test-dataset.csv'):\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(chkpt_path)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(chkpt_path)\n",
        "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    files_basepath = Path(files_basepath)\n",
        "    test_meta_df = pd.read_csv(test_meta_df)\n",
        "\n",
        "    preds = []\n",
        "    labels = []\n",
        "\n",
        "    for ix, row in test_meta_df.iterrows():\n",
        "        file_name = row.ID + '.pdf'\n",
        "        file_path = files_basepath / file_name\n",
        "        class_ix = infer(model, tokenizer, dst_file=str(file_path), dbg=False)\n",
        "        # class_ix = infer(model, tokenizer, url=row.URL, dbg=False)\n",
        "        true_label = row['Is lighting product?']\n",
        "        # print(f'{ix} - {class_ix} - {true_label}')\n",
        "        preds.append(class_ix)\n",
        "        labels.append(true_label)\n",
        "\n",
        "    preds = np.array(preds)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    correct = (preds == labels).sum().item()\n",
        "    tp = ((preds == 1) & (labels == 1)).sum()\n",
        "    tn = ((preds == 0) & (labels == 0)).sum()\n",
        "    fp = ((preds == 1) & (labels == 0)).sum()\n",
        "    fn = ((preds == 0) & (labels == 1)).sum()\n",
        "\n",
        "    print(f'Accuracy: {correct / len(labels)}')\n",
        "\n",
        "    print(f'TP: {tp} \\t| FN: {fn}')\n",
        "    print(f'FP: {fp} \\t| TN: {tn}')\n"
      ],
      "metadata": {
        "id": "7u_79OAxMgnd"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RUN EVALUATION ON PROVIDED TEST DATA"
      ],
      "metadata": {
        "id": "HaEeXjd3Wmq5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(chkpt_path='/content/parspec/checkpoints/checkpoint-270', files_basepath='parspec/data/test', test_meta_df='parspec/data/test-dataset.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFvmFcqoPV0V",
        "outputId": "457777bc-b303-4aa8-b464-44f7058c1240"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2869 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.875\n",
            "TP: 16 \t| FN: 4\n",
            "FP: 6 \t| TN: 54\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# INFERENCE"
      ],
      "metadata": {
        "id": "kkgFcEQCWs82"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "\n",
        "chkpt_path = '/content/parspec/checkpoints/checkpoint-270'\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(chkpt_path)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(chkpt_path).to(device)\n",
        "model.eval()\n",
        "\n",
        "\n",
        "url = 'https://www.cooperlighting.com/api/assets/v1/file/CLS/content/347f567de4414421a1dcad3f014a0c77/corelite-continua-sq4-brochure'\n",
        "infer(model, tokenizer, url=url, dbg=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvI2NIDjVVXQ",
        "outputId": "06b8abec-6d5e-430e-a0f8-990d70c45639"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully downloaded https://www.cooperlighting.com/api/assets/v1/file/CLS/content/347f567de4414421a1dcad3f014a0c77/corelite-continua-sq4-brochure\n",
            "Download successful\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2440 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text extraction successful\n",
            "Is lighting product? YES\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KQ_pm4jCXD8w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}